{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P1 : read csv file( the result of plugins searched and prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_searched</th>\n",
       "      <th>fetched_date</th>\n",
       "      <th>publishedAt_hour</th>\n",
       "      <th>published_date</th>\n",
       "      <th>description</th>\n",
       "      <th>video_tags</th>\n",
       "      <th>vd_category</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>dislikeCount</th>\n",
       "      <th>score3</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cashmirino</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>19</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Cashmirino’s cashmere pieces are handmade and ...</td>\n",
       "      <td>[u'cashmere', u'children clothing', u'children...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.724276</td>\n",
       "      <td>1.7160033436347992</td>\n",
       "      <td>1.724276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Armand Basi</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>14</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Null]</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.567026</td>\n",
       "      <td>2.5658478186735176</td>\n",
       "      <td>2.567026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cimalpes</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>Cimalpes a le plaisir de vous accueillir dans ...</td>\n",
       "      <td>[u'lifestyle', u'luxury lifestyle', u'luxury s...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.340444</td>\n",
       "      <td>2.3384564936046046</td>\n",
       "      <td>2.340444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Max Mara</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>16</td>\n",
       "      <td>2016-09-08</td>\n",
       "      <td>Six pairs of super stylish, real-life women sh...</td>\n",
       "      <td>[u'Max Mara', u'maxmara', u'Max Mara Official ...</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>25658</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>7.598316</td>\n",
       "      <td>28.51217712128986</td>\n",
       "      <td>74.507892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Swarovski</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-09-19</td>\n",
       "      <td>Crystaldust: a new must-have bracelet. Discove...</td>\n",
       "      <td>[u'Swarovski']</td>\n",
       "      <td>24</td>\n",
       "      <td>53</td>\n",
       "      <td>521188</td>\n",
       "      <td>0</td>\n",
       "      <td>324</td>\n",
       "      <td>6</td>\n",
       "      <td>9.961267</td>\n",
       "      <td>54.859362411391615</td>\n",
       "      <td>101.221005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  video_searched fetched_date  publishedAt_hour published_date  \\\n",
       "0     Cashmirino   2017-05-23                19     2016-01-01   \n",
       "1    Armand Basi   2017-05-23                14     2016-04-04   \n",
       "2       Cimalpes   2017-05-23                10     2016-04-06   \n",
       "3       Max Mara   2017-05-23                16     2016-09-08   \n",
       "4      Swarovski   2017-05-23                11     2016-09-19   \n",
       "\n",
       "                                         description  \\\n",
       "0  Cashmirino’s cashmere pieces are handmade and ...   \n",
       "1                                                NaN   \n",
       "2  Cimalpes a le plaisir de vous accueillir dans ...   \n",
       "3  Six pairs of super stylish, real-life women sh...   \n",
       "4  Crystaldust: a new must-have bracelet. Discove...   \n",
       "\n",
       "                                          video_tags  vd_category  \\\n",
       "0  [u'cashmere', u'children clothing', u'children...           22   \n",
       "1                                             [Null]           22   \n",
       "2  [u'lifestyle', u'luxury lifestyle', u'luxury s...           19   \n",
       "3  [u'Max Mara', u'maxmara', u'Max Mara Official ...           26   \n",
       "4                                     [u'Swarovski']           24   \n",
       "\n",
       "   commentCount  viewCount  favoriteCount  likeCount  dislikeCount    score3  \\\n",
       "0             0         52              0          0             0  1.724276   \n",
       "1             0        368              0          0             0  2.567026   \n",
       "2             0        218              0          0             0  2.340444   \n",
       "3            11      25658              0        128            40  7.598316   \n",
       "4            53     521188              0        324             6  9.961267   \n",
       "\n",
       "               score1      score2  \n",
       "0  1.7160033436347992    1.724276  \n",
       "1  2.5658478186735176    2.567026  \n",
       "2  2.3384564936046046    2.340444  \n",
       "3   28.51217712128986   74.507892  \n",
       "4  54.859362411391615  101.221005  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = pd.read_csv('youtube_searchbychannel_readitems_prepared.csv')\n",
    "yt = yt.drop(['video_id','video_title'],axis=1)\n",
    "yt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It includes the infomation as follows:   \n",
    "\n",
    "brand searched, searched date, the video published date and hour, video desription, video tags, video catogory, and comments, views, likes, dislikes, favorites for this video, 3 types of scores to evaluate brand fame (notoriété)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after read csv file, the format list is treated as string, so we have to change it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_searched</th>\n",
       "      <th>fetched_date</th>\n",
       "      <th>publishedAt_hour</th>\n",
       "      <th>published_date</th>\n",
       "      <th>description</th>\n",
       "      <th>video_tags</th>\n",
       "      <th>vd_category</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>dislikeCount</th>\n",
       "      <th>score3</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cashmirino</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>19</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Cashmirino’s cashmere pieces are handmade and ...</td>\n",
       "      <td>[u'cashmere', u'children clothing', u'children...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.724276</td>\n",
       "      <td>1.7160033436347992</td>\n",
       "      <td>1.724276</td>\n",
       "      <td>[u'cashmere',  u'children clothing',  u'childr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Armand Basi</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>14</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Null]</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.567026</td>\n",
       "      <td>2.5658478186735176</td>\n",
       "      <td>2.567026</td>\n",
       "      <td>[Null]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cimalpes</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>Cimalpes a le plaisir de vous accueillir dans ...</td>\n",
       "      <td>[u'lifestyle', u'luxury lifestyle', u'luxury s...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.340444</td>\n",
       "      <td>2.3384564936046046</td>\n",
       "      <td>2.340444</td>\n",
       "      <td>[u'lifestyle',  u'luxury lifestyle',  u'luxury...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Max Mara</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>16</td>\n",
       "      <td>2016-09-08</td>\n",
       "      <td>Six pairs of super stylish, real-life women sh...</td>\n",
       "      <td>[u'Max Mara', u'maxmara', u'Max Mara Official ...</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>25658</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>7.598316</td>\n",
       "      <td>28.51217712128986</td>\n",
       "      <td>74.507892</td>\n",
       "      <td>[u'Max Mara',  u'maxmara',  u'Max Mara Officia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Swarovski</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-09-19</td>\n",
       "      <td>Crystaldust: a new must-have bracelet. Discove...</td>\n",
       "      <td>[u'Swarovski']</td>\n",
       "      <td>24</td>\n",
       "      <td>53</td>\n",
       "      <td>521188</td>\n",
       "      <td>0</td>\n",
       "      <td>324</td>\n",
       "      <td>6</td>\n",
       "      <td>9.961267</td>\n",
       "      <td>54.859362411391615</td>\n",
       "      <td>101.221005</td>\n",
       "      <td>[u'Swarovski']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  video_searched fetched_date  publishedAt_hour published_date  \\\n",
       "0     Cashmirino   2017-05-23                19     2016-01-01   \n",
       "1    Armand Basi   2017-05-23                14     2016-04-04   \n",
       "2       Cimalpes   2017-05-23                10     2016-04-06   \n",
       "3       Max Mara   2017-05-23                16     2016-09-08   \n",
       "4      Swarovski   2017-05-23                11     2016-09-19   \n",
       "\n",
       "                                         description  \\\n",
       "0  Cashmirino’s cashmere pieces are handmade and ...   \n",
       "1                                                NaN   \n",
       "2  Cimalpes a le plaisir de vous accueillir dans ...   \n",
       "3  Six pairs of super stylish, real-life women sh...   \n",
       "4  Crystaldust: a new must-have bracelet. Discove...   \n",
       "\n",
       "                                          video_tags  vd_category  \\\n",
       "0  [u'cashmere', u'children clothing', u'children...           22   \n",
       "1                                             [Null]           22   \n",
       "2  [u'lifestyle', u'luxury lifestyle', u'luxury s...           19   \n",
       "3  [u'Max Mara', u'maxmara', u'Max Mara Official ...           26   \n",
       "4                                     [u'Swarovski']           24   \n",
       "\n",
       "   commentCount  viewCount  favoriteCount  likeCount  dislikeCount    score3  \\\n",
       "0             0         52              0          0             0  1.724276   \n",
       "1             0        368              0          0             0  2.567026   \n",
       "2             0        218              0          0             0  2.340444   \n",
       "3            11      25658              0        128            40  7.598316   \n",
       "4            53     521188              0        324             6  9.961267   \n",
       "\n",
       "               score1      score2  \\\n",
       "0  1.7160033436347992    1.724276   \n",
       "1  2.5658478186735176    2.567026   \n",
       "2  2.3384564936046046    2.340444   \n",
       "3   28.51217712128986   74.507892   \n",
       "4  54.859362411391615  101.221005   \n",
       "\n",
       "                                                tags  \n",
       "0  [u'cashmere',  u'children clothing',  u'childr...  \n",
       "1                                             [Null]  \n",
       "2  [u'lifestyle',  u'luxury lifestyle',  u'luxury...  \n",
       "3  [u'Max Mara',  u'maxmara',  u'Max Mara Officia...  \n",
       "4                                     [u'Swarovski']  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = yt.copy()\n",
    "y1['tags'] = y1['video_tags']\n",
    "\n",
    "y1['tags'] = y1['tags'].map(lambda x : x[1:-1])\n",
    "y1['tags'] = y1['tags'].map(lambda x : x.split(','))\n",
    "\n",
    "y1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the function here realises 2 goals :     \n",
    "1) fusionner des tags dont marques sont mêmes;\n",
    "2) réaliser une traduction des tags qui ne sont pas écrit en anglais (Normalisation)  \n",
    "This step takes a long time, you'd better save the results to be more quick next time;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import codecs\n",
    "from textblob import TextBlob\n",
    "import textblob\n",
    "\n",
    "def add_tags(l_tags,l):\n",
    "    l = [i.replace(\"Null\",\"\") for i in l]\n",
    "    #l_new = [i.replace(\" u'\",\"u'\") for i in l]\n",
    "    l = [i.replace(\"u'\",\"'\") for i in l]\n",
    "    \n",
    "    temps = copy.deepcopy(l)\n",
    "    for k in range(len(l)):\n",
    "        #if re.search(r'\\\\',l[k]) != None:\n",
    "            #print ('before',l[k])\n",
    "        temps[k] = codecs.decode(l[k],'unicode_escape')\n",
    "        blob = TextBlob(temps[k])\n",
    "        if blob.detect_language != 'en' :#and blob.detect_language != 'fr' :\n",
    "            try:\n",
    "                trans = str(blob.translate(to='en'))\n",
    "            except textblob.exceptions.NotTranslated:\n",
    "                #print (l[k],'this translation does not make changes.')\n",
    "                pass\n",
    "            else:\n",
    "                temps[k] = trans\n",
    "    #print (temps[:3])\n",
    "    [l_tags.append(i)  for i in temps]\n",
    "    return l_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y2 = y1.sort_values(['video_searched'],ascending=True)\n",
    "y2 = y2.reset_index()\n",
    "y2 = y2.drop('index',axis=1)\n",
    "\n",
    "\n",
    "list_tags = add_tags([],y2['tags'][2534])\n",
    "#list_brand_tags = []\n",
    "#count = 0\n",
    "\n",
    "for i in range(2535,len(y2)):\n",
    "    if y2['video_searched'][i] == y2['video_searched'][i-1]:\n",
    "        list_tags = add_tags(list_tags,y2['tags'][i])\n",
    "    else:\n",
    "        count = count+1\n",
    "        list_brand_tags.append([y2['video_searched'][i-1], list_tags])\n",
    "        print (i,count,y2['video_searched'][i-1],list_tags[:3],'\\n')\n",
    "        list_tags = add_tags([],y2['tags'][i])\n",
    "\n",
    "#translate = translate_tags(list_tags)\n",
    "list_brand_tags.append([y2['video_searched'][len(y2)-1], list_tags])\n",
    "\n",
    "     \n",
    "brand_tags = pd.DataFrame(list_brand_tags, columns=['brand','tags'])\n",
    "print (brand_tags.shape)\n",
    "print (brand_tags.iloc[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (brand_tags.shape)\n",
    "brand_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2 : text mining process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar (a,b):\n",
    "    return SequenceMatcher(None,a,b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (similar('apple','apples'))\n",
    "print (similar('adidas','Adidas'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "substitute similair spellings with the shortest one \n",
    "(to some degree, it avoids the mistake of singular or plural format, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_new = []\n",
    "for i in range(len(brand_tags)):\n",
    "\n",
    "    #order = df_tags['tags'][i].values.tolist()\n",
    "    order = brand_tags['tags'][i].copy()\n",
    "    list_arr = np.zeros(len(order))\n",
    "    #print (order)\n",
    "    for j in range(len(order)):\n",
    "        if list_arr[j] == 0:\n",
    "            for k in range(j+1,len(order)):\n",
    "                if similar(order[j],order[k]) == 1 and list_arr[k] != 1:\n",
    "                    list_arr[k] = 1\n",
    "                elif similar(order[j],order[k]) > 0.8 and list_arr[k] != 1:\n",
    "                    #print (\"yes,found some word with same meanings!\")\n",
    "                    #print (i,df_tags['brand'][i],df_tags['tags'][i][j],df_tags['tags'][i][k],'\\n\\n')\n",
    "                    if len(order[k]) > len(order[j]):\n",
    "                        order[k] = order[j]\n",
    "                    else:\n",
    "                        order[j] = order[k]\n",
    "                    list_arr[k] = 1\n",
    "    order = [x.lower()  for x in order]\n",
    "    print (i,order[:5])\n",
    "    list_new.append(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brand_tags['sub_tags'] = pd.Series(list_new)\n",
    "brand_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop certain rows with null tags (it does not make sense in later analyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_null = []\n",
    "for i in range(len(brand_tags)):\n",
    "    if brand_tags.sub_tags[i] == len(brand_tags.sub_tags[i])*[''] :\n",
    "        print (\"line\",i,brand_tags.brand[i],'cannot be validated.')\n",
    "        arr_null.append(i)\n",
    "brand_tags = brand_tags.drop(brand_tags.index[arr_null])\n",
    "brand_tags = brand_tags.reset_index()\n",
    "brand_tags = brand_tags.drop('index',axis=1)\n",
    "brand_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brand_tags.to_csv('brand_tags0606.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf\n",
    "tf-idf => svd to reduce the dimensionality => tsne to projection in 2 dimension (for better visualisation the final result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = set(stopwords.words('english')+stopwords.words('french')+stopwords.words('spanish'))\n",
    "\n",
    "df_analyse = brand_tags.copy()\n",
    "df_data = df_analyse.iloc[:,2:3]\n",
    "\n",
    "df_data['sub_tags'] = [ ' '.join(df_data['sub_tags'][i]) for i in range(len(df_data))]\n",
    "\n",
    "all_data = df_data.values.tolist()\n",
    "all_data = [','.join(all_data[i]) for i in range(len(all_data))]\n",
    "print (len(all_data))\n",
    "\n",
    "\n",
    "# (the constructor options use_idf=False, norm=None) the same as CountVectorizer\n",
    "# Tfidf vectorizer:\n",
    "#   - Strips out “stop words”\n",
    "#   - Filters out terms that occur in more than half of the docs (max_df=0.5)\n",
    "#   - Filters out terms that occur in only one document (min_df=2).\n",
    "#   - Selects the 10,000 most frequently occuring words in the corpus.\n",
    "#   - Normalizes the vector (L2 norm of 1.0) to normalize the effect of \n",
    "#     document length on the tf-idf values. \n",
    "\n",
    "#vectorizer = TfidfVectorizer(use_idf=True,stop_words=stop)\n",
    "vectorizer = TfidfVectorizer(max_df=0.8,min_df=30,use_idf=True,stop_words=stop)\n",
    "X = vectorizer.fit_transform(all_data)\n",
    "word = vectorizer.get_feature_names()\n",
    "print (X.shape)  \n",
    "print (word)\n",
    "#print (X.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#svd\n",
    "\n",
    "svd = TruncatedSVD(n_components=20)\n",
    "lsa = make_pipeline(svd,Normalizer(copy=False))\n",
    "\n",
    "svd_trans = lsa.fit_transform(X)\n",
    "#print (svd.explained_variance_ratio_)\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print (explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tsne\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "t_sne = TSNE(n_components=2,init='pca',perplexity=50,random_state=60,n_iter=5000)\n",
    "tsne_model = t_sne.fit_transform(svd_trans)\n",
    "np.set_printoptions(suppress=True)\n",
    "#print (t_sne_model_3)\n",
    "\n",
    "print (t_sne.kl_divergence_)\n",
    "print (t_sne.embedding_)\n",
    "\n",
    "df_tsne = pd.DataFrame(tsne_model)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "# make the scatter\n",
    "scat = plt.scatter(df_tsne.iloc[:,0], df_tsne.iloc[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans and Visualisation\n",
    "define the number of kmeans centers : when scores of kmeans do not change so much, we then choose the value with highest silhouette score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "center_iner = []\n",
    "center_score = []\n",
    "\n",
    "for k in  np.arange(5,55,5):\n",
    "    km = KMeans(n_clusters=k, n_init=10, random_state=60).fit(svd_trans)\n",
    "    res.append(metrics.silhouette_score(svd_trans, km.labels_))\n",
    "    center_iner.append(km.inertia_)\n",
    "    center_score.append(km.score(svd_trans))\n",
    "\n",
    "    #print (k/5-2)\n",
    "print(res)\n",
    "\n",
    "#graphique\n",
    "plt.title(\"Silhouette\")\n",
    "plt.xlabel(\"# of clusters\")\n",
    "plt.plot(np.arange(10), res)\n",
    "plt.plot(np.arange(10), center_iner,'-b',label='inertia')\n",
    "#plt.plot(np.arange(10,100,10), center_score,'-r',label='score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "center = 25\n",
    "# pay attention here we use X instead of scale(X)\n",
    "km3 = KMeans(n_clusters = center, init='k-means++', n_init=10, random_state=60).fit(svd_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_visual = df_tsne.copy()\n",
    "df_visual['label'] = pd.DataFrame(km3.labels_)\n",
    "print (df_visual.head())\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "N = 25\n",
    "ax = plt.subplot(111)\n",
    "cmap = plt.cm.jet\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "bounds = np.linspace(0,N,N+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "scat = ax.scatter(df_visual.iloc[:,0],df_visual.iloc[:,1],c=df_visual.label,cmap=cmap,norm=norm)\n",
    "cb = plt.colorbar(scat, spacing='proportional',ticks=bounds).set_label('Clustering map')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list : important words en terms of tags corresponding to th number of clustering\n",
    "df_visual['brand'] = brand_tags.brand\n",
    "df_visual.columns = ['x','y','label','brand']\n",
    "km_index = df_visual.sort_values(by=['label'],ascending=[True])\n",
    "km_index= km_index.reset_index()\n",
    "print (km_index.head())\n",
    "\n",
    "\n",
    "original_space_centroids = svd.inverse_transform(km3.cluster_centers_)\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "\n",
    "\n",
    "word = []\n",
    "\n",
    "terms = vectorizer.get_feature_names()\n",
    "print (len(terms))\n",
    "\n",
    "for i in range(center):\n",
    "    arr3 = []\n",
    "    for ind in order_centroids[i, :3]:\n",
    "        arr3.append(terms[ind])\n",
    "    word.append([arr3])\n",
    "    \n",
    "key_W = pd.DataFrame(word, columns=['important_tags'])\n",
    "key_W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this csv file is very important because it contains all the necessary infomations for brands ( the brand name, the position information in tsne matrix, the clustering result of kmeans )\n",
    "then we can create a matrix of similarity for brands using these position informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km_index.to_csv('yt_tags_sorted0606.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P3 :  create a linked network (brand&group, group&tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculer each gravity centre for each clustering group\n",
    "\n",
    "gravity = []\n",
    "\n",
    "pos_x = [km_index.iloc[0,1]]\n",
    "pos_y = [km_index.iloc[0,2]]\n",
    "\n",
    "for i in range(1,len(km_index)):\n",
    "    if km_index.label[i] == km_index.label[i-1]:\n",
    "        pos_x.append(km_index.iloc[i,1])\n",
    "        pos_y.append(km_index.iloc[i,2])\n",
    "    else:\n",
    "        #print (i,sum(pos_x),len(pos_x),sum(pos_x)/float(len(pos_x)), sum(pos_y)/float(len(pos_y)))\n",
    "        gravity.append([sum(pos_x)/float(len(pos_x)), sum(pos_y)/float(len(pos_y))])\n",
    "        pos_x = [km_index.iloc[i,1]]\n",
    "        pos_y = [km_index.iloc[i,2]]\n",
    "\n",
    "        \n",
    "gravity.append([sum(pos_x)/float(len(pos_x)), sum(pos_y)/float(len(pos_y))])\n",
    "print (len(gravity))\n",
    "df_gravity = pd.DataFrame(gravity,columns=['x','y'])\n",
    "df_gravity['tags'] = key_W.important_tags\n",
    "print (df_gravity.head())\n",
    "df_gravity.to_csv('yt_tags_gravity0606.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_gravity_new = df_gravity.copy()\n",
    "#df_gravity_new[['tags1','tags2','tags3','tags4','tags5']] = pd.DataFrame([x for x in df_gravity.tags])\n",
    "df_gravity_new[['tags1','tags2','tags3']] = pd.DataFrame([x for x in df_gravity.tags])\n",
    "#df_gravity_new[['tags1','tags2']] = pd.DataFrame([x for x in df_gravity.tags])\n",
    "df_gravity_new = df_gravity_new.drop('tags', axis=1)\n",
    "df_gravity_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_tags = []\n",
    "weight_tags = []\n",
    "count_tags = 0\n",
    "\n",
    "for i in range(len(df_gravity_new)):\n",
    "    for j in range(3):\n",
    "        if (df_gravity_new.iloc[i,j+2] in list_tags) == False:\n",
    "            list_tags.append(df_gravity_new.iloc[i,j+2])\n",
    "            weight_tags.append(j*0.5+1)\n",
    "            count_tags = count_tags+1\n",
    "        else:\n",
    "            ind = list_tags.index(df_gravity_new.iloc[i,j+2])\n",
    "            weight_tags[ind] = weight_tags[ind]+(j*0.5+1)\n",
    "\n",
    "print (count_tags)\n",
    "print (len(list_tags),len(weight_tags),list_tags[:5],weight_tags[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "pos = deepcopy(gravity)\n",
    "count_gravity = len(gravity)\n",
    "pos_tags = []\n",
    "for i in range(count_tags):\n",
    "    pos_tags.append((3*(i%10)-10,60-10*(i-i%10)/10+5*(i%2)))\n",
    "    #pos_tags.append((5*(i-i%16)/16+2*(i%2)-20,(i%16)+30))\n",
    "pos_points = []\n",
    "[pos_points.append((df_visual.iloc[i,0],df_visual.iloc[i,1]))  for i in range(len(df_visual))]\n",
    "pos = pos+pos_tags+pos_points\n",
    "G.add_nodes_from(range(len(pos)))\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=range(count_gravity),node_color='yellow',node_size=60)    \n",
    "nx.draw_networkx_nodes(G,pos,nodelist=range(count_gravity,count_gravity+count_tags),node_color='orange',alpha=0.3,node_size=[50*i  for i in weight_tags])\n",
    "#nx.draw_networkx_nodes(G,pos,nodelist=range(count_gravity+count_tags,len(pos)),node_color='green',node_size=10)\n",
    "\n",
    "edges_premier = []\n",
    "#edges = []\n",
    "width_edges_premier = []\n",
    "#width_edges = []\n",
    "for i in range(len(df_gravity_new)):\n",
    "    edges_premier.append((i,list_tags.index(df_gravity_new.tags1[i])+count_gravity))\n",
    "    #edges.append((i,list_tags.index(df_gravity_new.tags2[i])+count_gravity))\n",
    "    #edges.append((i,list_tags.index(df_gravity_new.tags3[i])+count_gravity))\n",
    "    width_edges_premier.append(2.0)\n",
    "    #width_edges.append(1.5)\n",
    "    #width_edges.append(1.0)\n",
    "    #edges.append((i,list_tags.index(df_gravity_new.tags4[i])+length_cluster))\n",
    "    #edges.append((i,list_tags.index(df_gravity_new.tags5[i])+length_cluster))\n",
    "\n",
    "    \n",
    "ensemble_edges = []\n",
    "\n",
    "for i in range(len(df_gravity_new)):\n",
    "    ensemble_edges.append((i,list_tags.index(df_gravity_new.tags1[i])+count_gravity))\n",
    "    ensemble_edges.append((i,list_tags.index(df_gravity_new.tags2[i])+count_gravity))\n",
    "    ensemble_edges.append((i,list_tags.index(df_gravity_new.tags3[i])+count_gravity))    \n",
    "    \n",
    "    \n",
    "#nx.draw_networkx_edges(G,pos,edgelist=edges,width=width_edges,edge_color='grey')\n",
    "#nx.draw_networkx_edges(G,pos,edgelist=edges_premier,width=width_edges_premier,edge_color='grey')\n",
    "G.add_edges_from(ensemble_edges)\n",
    "\n",
    "edges_new = []\n",
    "for i in range(len(df_visual)):\n",
    "    edges_new.append((i+count_gravity+count_tags,df_visual.label[i]))\n",
    "#nx.draw_networkx_edges(G,pos,edgelist=edges_new,width=1,alpha=0.5,edge_color='pink')    \n",
    "G.add_edges_from(edges_new)\n",
    "\n",
    "\n",
    "#print (G.nodes())\n",
    "labels = {}\n",
    "seuil = 3\n",
    "for i in range(count_gravity):\n",
    "    labels[i] = i\n",
    "for i in range(count_tags):\n",
    "    if weight_tags[i] > seuil:\n",
    "        labels[len(gravity)+i] = list_tags[i]\n",
    "\n",
    "arr_a = []        \n",
    "edges = []\n",
    "for a,b in ensemble_edges:\n",
    "    if weight_tags[b-count_gravity] > seuil:\n",
    "        edges.append((a,b))\n",
    "        arr_a.append(a)\n",
    "\n",
    "edges_brand = []\n",
    "arr_brand = []\n",
    "for a,b in edges_new:\n",
    "    if (b in arr_a) != False:\n",
    "        #print (a,b)\n",
    "        edges_brand.append((a,b))\n",
    "        arr_brand.append(a)\n",
    "        \n",
    "nx.draw_networkx_nodes(G,pos,nodelist=arr_brand,node_color='pink',node_size=10)\n",
    "nx.draw_networkx_labels(G,pos,labels,front_size=1)\n",
    "nx.draw_networkx_edges(G,pos,edgelist=edges,width=1,edge_color='grey',alpha=0.5)\n",
    "nx.draw_networkx_edges(G,pos,edgelist=edges_brand,width=1,alpha=0.2,edge_color='red')    \n",
    "G.add_edges_from(edges_brand)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P4 : analyse notoriété d youtube brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_youtube1 = y2.video_searched.values.tolist()\n",
    "list_youtube2 = km_index.brand.values.tolist()\n",
    "\n",
    "print (len(list_youtube1),len(list_youtube2))\n",
    "\n",
    "arr_label = []\n",
    "arr_alltags = []\n",
    "for i in range(len(y2)):\n",
    "    if (list_youtube1[i] in list_youtube2) == False:\n",
    "        arr_label.append(12)\n",
    "        arr_alltags.append(['Null'])\n",
    "    else:\n",
    "        ind = km_index['label'][list_youtube2.index(list_youtube1[i])]\n",
    "        arr_label.append(km_index['label'][list_youtube2.index(list_youtube1[i])])\n",
    "        arr_alltags.append(df_gravity['tags'][ind])\n",
    "        \n",
    "print (len(arr_label),arr_label[:5])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y2['label'] = pd.DataFrame(arr_label)\n",
    "y2['sub_tags'] = pd.Series(arr_alltags)\n",
    "y2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = y2.groupby(['label'])['score3'].transform(max) == y2['score3']\n",
    "y2_view_sort = y2[idx]\n",
    "y2_view_sort = y2_view_sort.reset_index()\n",
    "y2_view_sort = y2_view_sort.drop('index',axis=1)\n",
    "y2_view_sort.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yt_top10_brand = sorted(range(len(y2)), key=lambda k:y2.score2.values.tolist()[k],reverse=True)[:20]\n",
    "for i in yt_top10_brand:\n",
    "    print (y2.video_searched.values.tolist()[i],y2.score2.values.tolist()[i],y2.sub_tags[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(y2_view_sort)):\n",
    "    print (y2_view_sort.video_searched.values.tolist()[i],y2_view_sort.score2.values.tolist()[i],y2_view_sort.sub_tags[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
